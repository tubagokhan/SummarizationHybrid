{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOYJb2cCKpRi8hpw10oMb8d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tubagokhan/SummarizationHybrid/blob/main/OptimumClusterNumber.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torch\n",
        "!pip install scikit-learn\n",
        "!pip install matplotlib\n",
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "ThO6v86y2WAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from nltk import sent_tokenize\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import re\n",
        "\n",
        "from datasets import load_dataset\n",
        "from scipy.spatial import distance"
      ],
      "metadata": {
        "id": "CZfgFyRF3kb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing method\n",
        "def preprocess_corpus(text):\n",
        "    # Remove special characters and extra whitespaces\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s.]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "EETObHuc9vy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function calculates the optimal number of clusters using the elbow method. The function plots the elbow curve, which shows the inertia values for different cluster numbers. The user can visually inspect the plot to determine the elbow point, indicating the optimal number of clusters.\n",
        "def find_optimum_clusters(data, max_clusters):\n",
        "    inertias = []\n",
        "    for k in range(1, max_clusters + 1):\n",
        "        kmeans = KMeans(n_clusters=k, random_state=0).fit(data)\n",
        "        inertias.append(kmeans.inertia_)\n",
        "\n",
        "    # Plotting the elbow curve\n",
        "    #plt.plot(range(1, max_clusters + 1), inertias)\n",
        "    #plt.xlabel(\"Number of Clusters\")\n",
        "    #plt.ylabel(\"Inertia\")\n",
        "    #plt.title(\"Elbow Curve\")\n",
        "    #plt.show()\n",
        "\n",
        "    # Calculate the optimal number of clusters using the elbow method\n",
        "    diff = np.diff(inertias)\n",
        "    acceleration = np.diff(diff)\n",
        "    opt_cluster_num = acceleration.argmin() + 2  # Adding 2 to get the index of the minimum acceleration\n",
        "    return opt_cluster_num"
      ],
      "metadata": {
        "id": "R5n2jcYW7Z_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHQjZaUt2Lax"
      },
      "outputs": [],
      "source": [
        "def createSummaryUsingKMeans(corpus, modelName):\n",
        "    sentences = sent_tokenize(corpus)\n",
        "    model = SentenceTransformer(modelName)\n",
        "    sentence_embeddings = model.encode(sentences)\n",
        "\n",
        "    optimum_clusters = find_optimum_clusters(sentence_embeddings, int(len(sentences) / 3))\n",
        "    print(\"Optimum cluster number:\", optimum_clusters)\n",
        "\n",
        "    # Perform kmean clustering\n",
        "    kmeans = KMeans(n_clusters=optimum_clusters, random_state=0, n_init='auto').fit(sentence_embeddings)\n",
        "\n",
        "    chosen_sentence_indexes=[]\n",
        "    for cluster_id in range(optimum_clusters):\n",
        "        cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]\n",
        "        sorted_cluster_indices = sorted(cluster_indices, key=lambda x: sentences[x])\n",
        "        chosen_sentence_index = sorted_cluster_indices[0]  # Select the first sentence from the sorted indices\n",
        "        chosen_sentence_indexes.append(chosen_sentence_index)\n",
        "\n",
        "    sorted_indexes=sorted(chosen_sentence_indexes)\n",
        "\n",
        "    chosen_sentences = []\n",
        "    for chosen_sentence_index in sorted_indexes:\n",
        "        chosen_sentences.append(sentences[chosen_sentence_index])\n",
        "\n",
        "    summary = \" \".join(chosen_sentences)\n",
        "\n",
        "    return summary\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MAIN\n",
        "\n",
        "dataset = load_dataset('cnn_dailymail', '3.0.0')\n",
        "corpus = dataset['train']['article'][50]\n",
        "\n",
        "\n",
        "#dataset = load_dataset(\"ccdv/govreport-summarization\")\n",
        "#corpus= dataset['train']['report'][100]\n",
        "corpus = preprocess_corpus(corpus)\n",
        "\n",
        "\n",
        "modelName='all-mpnet-base-v2'\n",
        "\n",
        "summary=createSummaryUsingKMeans(corpus, modelName)\n",
        "print(corpus)\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "BrKrlYxN3auN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}